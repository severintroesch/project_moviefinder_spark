{"cells":[{"cell_type":"markdown","source":["ZHAW, CAS Information Engineering, Module Big Data, December 2019  \n  \nFinal Project **Christophe Otter & Severin Troesch**\n\n## Movie Finder: Performance gain with Spark\n  \n##### *V7 - 06.01.2019*"],"metadata":{}},{"cell_type":"markdown","source":["### 1. Preparation Python\n\nWhat we want in this section is the following:  \n  \n- Install and load the necessary modules\n- Load the dataset (written plots of 35k movies)\n- Convert the data into a python list for the \"baseline\" assessment of the performance"],"metadata":{}},{"cell_type":"markdown","source":["First, lets download and import the necessary modules:"],"metadata":{}},{"cell_type":"code","source":["## installing the external modules via library utilities (are available on notebook session level)\ndbutils.library.installPyPI('nltk')\nimport nltk\nnltk.download('stopwords')\nnltk.download('punkt') #used for nltk.word_tokenize function"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">[nltk_data] Downloading package stopwords to /root/nltk_data...\n[nltk_data]   Unzipping corpora/stopwords.zip.\n[nltk_data] Downloading package punkt to /root/nltk_data...\n[nltk_data]   Unzipping tokenizers/punkt.zip.\n<span class=\"ansired\">Out[</span><span class=\"ansired\">1</span><span class=\"ansired\">]: </span>True</div>"]}}],"execution_count":4},{"cell_type":"code","source":["## import modules\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport time\nimport os\nimport re\n# import nltk #language processing, imported above\nfrom nltk.corpus import stopwords\nstopw = set(stopwords.words('english')) # set of stopwords\nimport math\nimport json\nimport numpy"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":5},{"cell_type":"markdown","source":["Then, lets get the data (upload movies-database as .csv manually to /FileStore/tables/):  \nPath: /FileStore/tables/movies_df.csv"],"metadata":{}},{"cell_type":"markdown","source":["Now, we load the csv with pandas - and convert the relevant column into a python-list."],"metadata":{}},{"cell_type":"code","source":["## Then, load csv, but with regular pandas-commands - for speed comparison later\nmovies_pd = pd.read_csv(\"/dbfs/FileStore/tables/movies_df.csv\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":8},{"cell_type":"code","source":["## have a look\nmovies_pd.head() #looks ok - a regular pandas df that is"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<div style=\"max-width:1500px;overflow:auto;\">\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Release Year</th>\n      <th>Title</th>\n      <th>Origin/Ethnicity</th>\n      <th>Director</th>\n      <th>Cast</th>\n      <th>Genre</th>\n      <th>Wiki Page</th>\n      <th>Plot</th>\n      <th>All</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1901</td>\n      <td>Kansas Saloon Smashers</td>\n      <td>American</td>\n      <td>Unknown</td>\n      <td>NaN</td>\n      <td>unknown</td>\n      <td>https://en.wikipedia.org/wiki/Kansas_Saloon_Sm...</td>\n      <td>A bartender is working at a saloon, serving dr...</td>\n      <td>A bartender is working at a saloon, serving dr...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1901</td>\n      <td>Love by the Light of the Moon</td>\n      <td>American</td>\n      <td>Unknown</td>\n      <td>NaN</td>\n      <td>unknown</td>\n      <td>https://en.wikipedia.org/wiki/Love_by_the_Ligh...</td>\n      <td>The moon, painted with a smiling face hangs ov...</td>\n      <td>The moon, painted with a smiling face hangs ov...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1901</td>\n      <td>The Martyred Presidents</td>\n      <td>American</td>\n      <td>Unknown</td>\n      <td>NaN</td>\n      <td>unknown</td>\n      <td>https://en.wikipedia.org/wiki/The_Martyred_Pre...</td>\n      <td>The film, just over a minute long, is composed...</td>\n      <td>The film, just over a minute long, is composed...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1901</td>\n      <td>Terrible Teddy, the Grizzly King</td>\n      <td>American</td>\n      <td>Unknown</td>\n      <td>NaN</td>\n      <td>unknown</td>\n      <td>https://en.wikipedia.org/wiki/Terrible_Teddy,_...</td>\n      <td>Lasting just 61 seconds and consisting of two ...</td>\n      <td>Lasting just 61 seconds and consisting of two ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1902</td>\n      <td>Jack and the Beanstalk</td>\n      <td>American</td>\n      <td>George S. Fleming, Edwin S. Porter</td>\n      <td>NaN</td>\n      <td>unknown</td>\n      <td>https://en.wikipedia.org/wiki/Jack_and_the_Bea...</td>\n      <td>The earliest known adaptation of the classic f...</td>\n      <td>The earliest known adaptation of the classic f...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":9},{"cell_type":"code","source":["# and make list of \"All\" variable to iterate over later (for the baseline comparison)\nmovies_ls = movies_pd.All.tolist()\ntype(movies_ls)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">11</span><span class=\"ansired\">]: </span>list</div>"]}}],"execution_count":10},{"cell_type":"code","source":["## check content\nmovies_ls[10] #good"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">6</span><span class=\"ansired\">]: </span>&apos;The Rarebit Fiend gorges on Welsh rarebit at a restaurant. When he leaves, he begins to get dizzy as he starts to hallucinate. He desperately tries to hang onto a lamppost as the world spins all around him. A man helps him get home. He falls into bed and begins having more hallucinatory dreams. During a dream sequence, the furniture begins moving around the room. Imps emerge from a floating Welsh rarebit container and begin poking his head as he sleeps. His bed then begins dancing and spinning wildly around the room before flying out the window with the Fiend in it. The bed floats across the city as the Fiend floats up and off the bed. He hangs off the back and eventually gets caught on a weathervane atop a steeple. His bedclothes tear and he falls from the sky, crashing through his bedroom ceiling. The Fiend awakens from the dream after falling out of his bed. Dream of a Rarebit Fiend Dream of a Rarebit Fiend Dream of a Rarebit Fiend Dream of a Rarebit Fiend Dream of a Rarebit Fiend Dream of a Rarebit Fiend Dream of a Rarebit Fiend Dream of a Rarebit Fiend Dream of a Rarebit Fiend Dream of a Rarebit Fiend American American American American American American American American American American Wallace McCutcheon and Edwin S. Porter Wallace McCutcheon and Edwin S. Porter Wallace McCutcheon and Edwin S. Porter Wallace McCutcheon and Edwin S. Porter Wallace McCutcheon and Edwin S. Porter Wallace McCutcheon and Edwin S. Porter Wallace McCutcheon and Edwin S. Porter Wallace McCutcheon and Edwin S. Porter Wallace McCutcheon and Edwin S. Porter Wallace McCutcheon and Edwin S. Porter nan nan nan nan nan nan nan nan nan nan shortshortshortshortshortshortshortshortshortshort&apos;</div>"]}}],"execution_count":11},{"cell_type":"markdown","source":["### 2. Python helper Functions\n\nWhat we want in this section is the following:\n\n- Define the helper functions for the movie finder - them same functions that were used in the python-implementation."],"metadata":{}},{"cell_type":"markdown","source":["Now, define the different helper functions necessary for the analysis of the dataset and for the movie-selection.  \n  \nFow now, just take the same functions as in the spyder-pathon-version of the movie-recommender:"],"metadata":{}},{"cell_type":"code","source":["## normalizer function\n\ndef nor(txt):\n    \n    ''' doc:\n       input (txt) = text string that needs to be normalised\n       output = a list of normalised tokens - NOT UNIQUE!\n    '''\n    \n    ## tokenize\n    #txt_2 = nltk.word_tokenize(txt) # this causes problems in .map functionality later...\n    txt_2 = txt.split() #tokenize \n    \n    ## remove stopwords\n    txt_2 = [word for word in txt_2 if word not in stopw]\n    \n    ## remove special characters and capitals\n    txt_2 = [re.sub(r'\\W+', '', word).lower() for word in txt_2]\n    \n    ## remove empty indexes\n    txt_2 = [word for word in txt_2 if len(word)>1]\n    \n    # return result: a list of normalised tokens - NOT UNIQUE! - and joined with named entities\n    return txt_2"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":14},{"cell_type":"code","source":["## check\nnor(\"bla is a word\") #works"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">6</span><span class=\"ansired\">]: </span>[&apos;bla&apos;, &apos;word&apos;]</div>"]}}],"execution_count":15},{"cell_type":"code","source":["## function for TF out of list of not-unique normalised tokens (result from nor() function)\n    \ndef tf(lis):\n    \n    ''' doc:\n       input: \n           lis = list of not-unique normalised tokens (result from nor() function)\n       output = a dict  with token and term freqencies\n    '''\n        \n    res = {} #dict of tokens in lis (key) and # occurances in lis (value)\n    cindex = set() #set of tokens in txt\n    \n    nt = len(lis) # number of tokens in txt\n    \n    # for every word in list\n    for t in lis:\n        if t not in cindex:\n            cindex.add(t)\n            res[t] = 1/nt # /nt gives the normalisation for the term-frequency\n        else:\n            res[t] += 1/nt\n    \n    ## return result - a dict of token and term freqencies\n    return res\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":16},{"cell_type":"code","source":["## idf function\n\n# function that calculates idf for tokens in a collection of documents\n# returns a dict (key = token, velue = idf)\n\ndef idf(coll):\n    \n    \"\"\"doc:\n    in: coll = list of of documents (strings of multiple tokens)\n    out: dictionary of tokens to idf of token in collection\n    \"\"\" \n    ts1 = round(time.time(),0) #timestamp 1\n    \n    N = len(coll)  \n    print(\"Analysing {} documents...\".format(N))\n    print()\n    \n    dic = {}\n    \n    # get a list of sets of normalised tokens\n    lss = [set(nor(doc)) for doc in coll] #returns a list of sets\n    \n    ts2 = round(time.time(),0) #timestamp 2\n    print(\"step 1 (normalising & TF of all movie-plot strings) done ... (took {} s)\".format(ts2-ts1))\n    \n    # set of all words in coll\n    settot = set()\n    for s in lss:\n        settot = settot.union(s)\n        \n    ts3 = round(time.time(),0) #timestamp 3\n    print(\"step 2 (merge all sets of normalised strings to one set) done ... (took {} s)\".format(ts3-ts2))\n        \n    # for all tokens in collection \n    for tok in list(settot):\n        nrdoc = 0\n        \n        # for all sets of tokens (i.e. documents)\n        for tokset in lss:\n            if tok in tokset:\n                nrdoc += 1 #nrdoc: in how many docs is the token?\n        \n        dic[tok] = N/nrdoc #idf = N / number of docs that contain tok\n    \n    ts4 = round(time.time(),0) #timestamp 4 \n    print(\"step 3 (for all tokens in all movies: determine idf) done ... (took {} s)\".format(ts4-ts3))\n    print()\n    print(\"finished. (overall analysis time: {} s)\".format(ts4 - ts1))\n    return dic"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":17},{"cell_type":"code","source":["## tfidf function: combine tf with idf - function takes string and gives dict of tokens:tfidf\n\ndef tfidf(txt, idfs):\n    \"\"\" Compute TF-IDF\n    Args:\n        txt: string\n        idfs (dictionary): token to IDF value\n    Returns:\n        dictionary: a dictionary of records to TF-IDF values\n    \"\"\"\n    tfs = tf(nor(txt)) #a dict of token and term freqencies\n    \n    resdict = {}\n    \n    for t in tfs:\n        if t in idfs:\n            resdict[t] = tfs[t] * idfs[t] #calculate TF-IDF\n        else:\n            resdict[t] = 0 #zero if word is NOT in idfs reference\n            \n    return resdict"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":18},{"cell_type":"markdown","source":["Now the ranking function (only cossim-function is applied, as the comparison between the ranking functions is not the point of this project):"],"metadata":{}},{"cell_type":"code","source":["## implement cosine-similarity function(s)\n\n# dot product and normalizing funs\ndef dotprod(a, b):\n    return sum([a[t] * b[t] for t in a if t in b])\n\ndef norm(a):\n    return math.sqrt(dotprod(a, a))\n\n# and finally, the actual fun to calculate cossim from two dicts\ndef cossim(dict1, dict2):\n    \"\"\" Compute cosine similarity between two strings\n    Args:\n        dict1: first dict of tokens and tf-idf values\n        dict2: second dict of tokens and tf-idf values\n\n    Returns:\n        cossim: cosine similarity value\n    \"\"\"\n\n    return dotprod(dict1, dict2) / norm(dict1) / norm(dict2)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":20},{"cell_type":"code","source":["## build ranking-function to compare query and corpus  - using cosine similarity\n    \ndef get_ranking_cossim(query, ref_dict, threshold, idf_dict):\n    \n    \"\"\" calculate and return a ranking of movies relative to searchstring (query)\n    input:\n        query = searchstring\n        ref_dict = reference dictionary of movies (title:dict(token:tfidf))\n        threshold = threshold reference score (default = 1) above which results are returned\n        idfs = reference dict with term idfs\n    output:\n        a sorted listof tuples (title, relevance score) with movies in decreasing similarity scores-order\n    \"\"\"\n    \n    ## first, apply tf() and nor() function to query\n    q = tfidf(query, idf_dict) #dict of query tokens:tfidf\n    \n    ## second, iterate over ref_dict and compare query to values (calculate relevance score)\n        ## the result is a dict with movie titles as key and the relevance score (rs) as value\n    res = {}\n    \n    for film in ref_dict: #all films in ref_dict\n        \n        \n        # calculate relevance score (cosine similarity)\n        rs = cossim(q,ref_dict[film])\n        \n        # add relevance score for film to res-dict\n        res[film] = rs \n        \n    ## define a sorted list with decreasing relevance scores\n    result1 = sorted(res.items(), key=lambda kv: kv[1], reverse = True)\n    # and choose items over threshold\n    result2 = [mov[0] for mov in result1 if mov[1] > threshold]\n             \n    ## finally, return result\n    return result2"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":21},{"cell_type":"markdown","source":["###3. Apply and time code from python-implementation\n\nWhat we want in this section is the following:\n\n- Apply the above-defined helper functions - build the same movie recommender as in the python-implementation.\n- Time the crucial steps - as baseline for later performance improvement (the two crucial parts are: idfs and res_dict)"],"metadata":{}},{"cell_type":"code","source":["## first, prepare the timing of the python-implementation\npy_pre = time.time()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":23},{"cell_type":"code","source":["## define number of rows in df that should be used for development\nn_test = 1000"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":24},{"cell_type":"code","source":["## idf-dict: make dict of idfs for movies (for lookup)\n\n# apply to n_test cases\n#idfs = idf(movies_ls[:n_test])\n\n# apply to whole list of movies\nidfs = idf(movies_ls)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Analysing 34886 documents...\n\nstep 1 (normalising &amp; TF of all movie-plot strings) done ... (took 33.0 s)\nstep 2 (merge all sets of normalised strings to one set) done ... (took 329.0 s)\nstep 3 (for all tokens in all movies: determine idf) done ... (took 788.0 s)\n\nfinished. (overall analysis time: 1150.0 s)\n</div>"]}}],"execution_count":25},{"cell_type":"code","source":["## check content\nidfs['steamboat'] #worked"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">17</span><span class=\"ansired\">]: </span>1836.1052631578948</div>"]}}],"execution_count":26},{"cell_type":"code","source":["## apply functions to  dataset - a dict results (title:list of tuples(title,TF))\n\nres_dict = {} #dictionary with titles (keys) and result dict (values). result dict is token:tfidf\nts_resdict1 = time.time() #timestamp 1\n\n# loop over movies  \n#for i, row in movies_pd.head(n_test).iterrows(): #only for n_test cases\nfor i, row in movies_pd.iterrows(): #for all cases\n\n    txt = row[\"All\"]\n    n_mov = i+1\n    \n    res_dict[row[\"Title\"]] = tfidf(txt, idfs) \n\nts_resdict2 = time.time() #timestamp 2\nsecs = round(ts_resdict2 - ts_resdict1,1) #analysis time\n\nprint(\"Analysed {} movies in {} seconds.\".format(n_mov, secs))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Analysed 34886 movies in 45.1 seconds.\n</div>"]}}],"execution_count":27},{"cell_type":"code","source":["## check content of result\nres_dict['The Girl Who Stayed at Home'] # looks ok"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">19</span><span class=\"ansired\">]: </span>{&apos;atoline&apos;: 157.14414414414415,\n &apos;additional&apos;: 0.6892287023865971,\n &apos;seymour&apos;: 1.4550383717050384,\n &apos;cabaret&apos;: 2.014668514668515,\n &apos;dw&apos;: 78.57207207207207,\n &apos;goes&apos;: 0.01681045615577066,\n &apos;adoration&apos;: 7.142915642915643,\n &apos;harron&apos;: 9.82150900900901,\n &apos;the&apos;: 0.07323222251377592,\n &apos;draft&apos;: 3.612509060784923,\n &apos;who&apos;: 0.8205960529720322,\n &apos;le&apos;: 1.8272574900481877,\n &apos;rescue&apos;: 0.06732825370357504,\n &apos;blossoms&apos;: 0.9189716031821294,\n &apos;older&apos;: 0.11718429839235207,\n &apos;return&apos;: 0.02563526005614097,\n &apos;younger&apos;: 0.07748725056417363,\n &apos;lestina&apos;: 576.1951951951952,\n &apos;as&apos;: 0.01697937808148505,\n &apos;confederate&apos;: 1.0476276276276275,\n &apos;after&apos;: 0.012422461987679378,\n &apos;carol&apos;: 4.401796754737932,\n &apos;adolf&apos;: 19.163920017578555,\n &apos;described&apos;: 0.46769090519090517,\n &apos;hole&apos;: 0.3022002772002772,\n &apos;film&apos;: 0.017906123990900656,\n &apos;flag&apos;: 0.7447589769864651,\n &apos;threatened&apos;: 0.2836536897908739,\n &apos;monsieur&apos;: 8.270744428639166,\n &apos;enlists&apos;: 0.37326400034238516,\n &apos;when&apos;: 0.024655863206110323,\n &apos;makes&apos;: 0.027112516242951024,\n &apos;meet&apos;: 0.0300065197907474,\n &apos;evade&apos;: 0.543751363820568,\n &apos;lives&apos;: 0.06644572691084319,\n &apos;father&apos;: 0.016347045058165418,\n &apos;swears&apos;: 0.543751363820568,\n &apos;behind&apos;: 0.038945264967569795,\n &apos;france&apos;: 1.587314587314587,\n &apos;griffith&apos;: 8.928644553644554,\n &apos;faithful&apos;: 0.7896690660509755,\n &apos;lines&apos;: 0.32135816798393485,\n &apos;world&apos;: 0.03790259144817755,\n &apos;soldier&apos;: 0.20172547386924794,\n &apos;continue&apos;: 0.07562278351498755,\n &apos;dempster&apos;: 192.06506506506508,\n &apos;blossom&apos;: 5.1522670211194805,\n &apos;german&apos;: 0.5693628411019716,\n &apos;brothers&apos;: 0.17392821709368472,\n &apos;officer&apos;: 0.05065897619089109,\n &apos;allegiance&apos;: 2.014668514668515,\n &apos;shell&apos;: 0.4895456203867419,\n &apos;remain&apos;: 0.1533113601406284,\n &apos;jim&apos;: 0.4742781010386644,\n &apos;singer&apos;: 0.13172183079978553,\n &apos;magazine3&apos;: 3.5714578214578214,\n &apos;brother&apos;: 0.032076779780392764,\n &apos;sweetheart&apos;: 0.385157216039569,\n &apos;comes&apos;: 0.020687749360735145,\n &apos;caught&apos;: 0.07165715647247795,\n &apos;another&apos;: 0.021005767162698055,\n &apos;sent&apos;: 0.050014049695781077,\n &apos;dramadramadramadramadramadramadramadramadramadrama&apos;: 0.026348783391036912,\n &apos;seeks&apos;: 0.13724379401235298,\n &apos;him&apos;: 0.010422772709699817,\n &apos;adventures&apos;: 0.45417382700619696,\n &apos;trenches&apos;: 4.02933702933703,\n &apos;beautiful&apos;: 0.0845770420582046,\n &apos;cutie&apos;: 104.76276276276276,\n &apos;civil&apos;: 0.3484349094105192,\n &apos;son&apos;: 0.022027494273078797,\n &apos;stayed&apos;: 8.97966537966538,\n &apos;barthelmess&apos;: 7.483054483054483,\n &apos;shot&apos;: 0.04836692648326997,\n &apos;training&apos;: 0.16284367268823227,\n &apos;grey&apos;: 0.85871117018658,\n &apos;befriended&apos;: 0.6953280714342661,\n &apos;patrol&apos;: 0.4081666081666082,\n &apos;ralph&apos;: 0.6186777328509612,\n &apos;catches&apos;: 0.10448413839371287,\n &apos;james&apos;: 0.06285765765765766,\n &apos;sweethearts&apos;: 2.7569148095463882,\n &apos;girl&apos;: 0.2768571954618466,\n &apos;american&apos;: 0.10503117576750194,\n &apos;two&apos;: 0.013023714913322075,\n &apos;promises&apos;: 0.09495114449797229,\n &apos;war&apos;: 0.08918509883322596,\n &apos;home&apos;: 0.1582837874135215,\n &apos;man&apos;: 0.015506625630959557}</div>"]}}],"execution_count":28},{"cell_type":"markdown","source":["Recommender should now work:"],"metadata":{}},{"cell_type":"code","source":["## check it it works\nget_ranking_cossim(\"France action drama new test movie tarantino\", \n                   ref_dict = res_dict, \n                   threshold = 0.03, \n                   idf_dict = idfs)\n\n# works."],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">53</span><span class=\"ansired\">]: </span>[&quot;My Best Friend&apos;s Birthday&quot;,\n &apos;Reservoir Dogs&apos;,\n &apos;From Dusk Till Dawn&apos;,\n &apos;Kill Bill Volume 2&apos;,\n &apos;Kill Bill Volume 1&apos;,\n &apos;Girl 6&apos;,\n &apos;Jackie Brown&apos;,\n &apos;Django Unchained&apos;,\n &apos;Pulp Fiction&apos;,\n &apos;Inglourious Basterds&apos;]</div>"]}}],"execution_count":30},{"cell_type":"code","source":["## and manifest the timing for the python implementation\npy_post = time.time()\nprint(\"The python-implementation took {} minutes overall.\".format(round((py_post - py_pre)/60,2)))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">The python-implementation took 19.98 minutes overall.\n</div>"]}}],"execution_count":31},{"cell_type":"markdown","source":["###4. Create the spark data structures\n\nWhat we want in this section is the following:\n\n- Create a spark-dataframe of movie-df for later parallelization\n- Create an RDD of the \"All\" variable list for later parallelization"],"metadata":{}},{"cell_type":"markdown","source":["So lets create the spark dataframe:"],"metadata":{}},{"cell_type":"code","source":["## load data from csv file - create DataFrame (notabene: this is an RDD)\n'''\nmovies = sqlContext.read.format(\"csv\")\\\n.option(\"header\",\"true\")\\\n.option(\"delimiter\", \",\")\\\n.option(\"inferSchema\", \"true\")\\\n.load(\"/FileStore/tables/movies_df.csv\")\n'''\n\n# this does not work somehow - the resulting dataframe has weiredly shifted columns"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">24</span><span class=\"ansired\">]: </span>&apos;\\nmovies = sqlContext.read.format(&quot;csv&quot;).option(&quot;header&quot;,&quot;true&quot;).option(&quot;delimiter&quot;, &quot;,&quot;).option(&quot;inferSchema&quot;, &quot;true&quot;).load(&quot;/FileStore/tables/movies_df.csv&quot;)\\n&apos;</div>"]}}],"execution_count":34},{"cell_type":"code","source":["## better: create spark dataframe from pandas df\nmovies_spk = sqlContext.createDataFrame(movies_pd.astype(str))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":35},{"cell_type":"code","source":["## cache the df\nmovies_spk.cache()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">5</span><span class=\"ansired\">]: </span>DataFrame[Release Year: string, Title: string, Origin/Ethnicity: string, Director: string, Cast: string, Genre: string, Wiki Page: string, Plot: string, All: string]</div>"]}}],"execution_count":36},{"cell_type":"code","source":["## check form\nmovies_spk.show(36) # looks ok"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+------------+--------------------+----------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\nRelease Year|               Title|Origin/Ethnicity|            Director|                Cast|               Genre|           Wiki Page|                Plot|                 All|\n+------------+--------------------+----------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n        1901|Kansas Saloon Sma...|        American|             Unknown|                 nan|             unknown|https://en.wikipe...|A bartender is wo...|A bartender is wo...|\n        1901|Love by the Light...|        American|             Unknown|                 nan|             unknown|https://en.wikipe...|The moon, painted...|The moon, painted...|\n        1901|The Martyred Pres...|        American|             Unknown|                 nan|             unknown|https://en.wikipe...|The film, just ov...|The film, just ov...|\n        1901|Terrible Teddy, t...|        American|             Unknown|                 nan|             unknown|https://en.wikipe...|Lasting just 61 s...|Lasting just 61 s...|\n        1902|Jack and the Bean...|        American|George S. Fleming...|                 nan|             unknown|https://en.wikipe...|The earliest know...|The earliest know...|\n        1903| Alice in Wonderland|        American|      Cecil Hepworth|           May Clark|             unknown|https://en.wikipe...|Alice follows a l...|Alice follows a l...|\n        1903|The Great Train R...|        American|     Edwin S. Porter|                 nan|             western|https://en.wikipe...|The film opens wi...|The film opens wi...|\n        1904|     The Suburbanite|        American|  Wallace McCutcheon|                 nan|              comedy|https://en.wikipe...|The film is about...|The film is about...|\n        1905|The Little Train ...|        American|Edwin Stanton Porter|                 nan|             unknown|https://en.wikipe...|The opening scene...|The opening scene...|\n        1905|The Night Before ...|        American|Edwin Stanton Porter|                 nan|             unknown|https://en.wikipe...|Scenes are introd...|Scenes are introd...|\n        1906|Dream of a Rarebi...|        American|Wallace McCutcheo...|                 nan|               short|https://en.wikipe...|The Rarebit Fiend...|The Rarebit Fiend...|\n        1906|From Leadville to...|        American|Francis J. Marion...|                 nan|short action/crim...|https://en.wikipe...|The film features...|The film features...|\n        1906| Kathleen Mavourneen|        American|     Edwin S. Porter|                 nan|          short film|https://en.wikipe...|Irish villager Ka...|Irish villager Ka...|\n        1907|        Daniel Boone|        American|Wallace McCutcheo...|William Craven, F...|        biographical|https://en.wikipe...|Boone&apos;s daughter ...|Boone&apos;s daughter ...|\n        1907|How Brown Saw the...|        American|             Unknown|             Unknown|              comedy|https://en.wikipe...|Before heading ou...|Before heading ou...|\n        1907|        Laughing Gas|        American|Edwin Stanton Porter|Bertha Regustus, ...|              comedy|https://en.wikipe...|The plot is that ...|The plot is that ...|\n        1908|The Adventures of...|        American|      D. W. Griffith|Arthur V. Johnson...|               drama|https://en.wikipe...|On a beautiful su...|On a beautiful su...|\n        1908|     The Black Viper|        American|      D. W. Griffith|      D. W. Griffith|               drama|https://en.wikipe...|A thug accosts a ...|A thug accosts a ...|\n        1908|A Calamitous Elop...|        American|       D.W. Griffith|Harry Solter, Lin...|              comedy|https://en.wikipe...|A young couple de...|A young couple de...|\n        1908|The Call of the Wild|        American|      D. W. Griffith|      Charles Inslee|           adventure|https://en.wikipe...|A white girl (Flo...|A white girl (Flo...|\n        1908|   A Christmas Carol|        American|             Unknown|        Tom Ricketts|               drama|https://en.wikipe...|No prints of the ...|No prints of the ...|\n        1908|The Fight for Fre...|        American|      D. W. Griffith|Florence Auer, Jo...|             western|https://en.wikipe...|The film opens in...|The film opens in...|\n        1909|        At the Altar|        American|      D. W. Griffith|      Marion Leonard|               drama|https://en.wikipe...|A rejected admire...|A rejected admire...|\n        1909|A Drunkard&apos;s Refo...|        American|      D. W. Griffith|   Arthur V. Johnson|               drama|https://en.wikipe...|John Wharton, the...|John Wharton, the...|\n        1909|    The Golden Louis|        American|      D. W. Griffith|                 nan|               drama|https://en.wikipe...|An old woman send...|An old woman send...|\n        1909|The Lure of the Gown|        American|       D.W. Griffith|      Marion Leonard|             unknown|https://en.wikipe...|The story as told...|The story as told...|\n        1910|    An Arcadian Maid|        American|       D.W. Griffith|Mary Pickford, Ma...|               drama|https://en.wikipe...|Mary Pickford pla...|Mary Pickford pla...|\n        1910|   A Christmas Carol|        American|    J. Searle Dawley|Marc McDermott, C...|             unknown|https://en.wikipe...|The day before Ch...|The day before Ch...|\n        1910|        Frankenstein|        American|    J. Searle Dawley|Augustus Phillips...|             unknown|https://en.wikipe...|Described as &quot;a l...|Described as &quot;a l...|\n        1910|Hemlock Hoax, the...|        American|             Unknown|                 nan|              comedy|https://en.wikipe...|Hemlock Hoax is a...|Hemlock Hoax is a...|\n        1910|The House with Cl...|        American|       D.W. Griffith|   Henry B. Walthall|               drama|https://en.wikipe...|During the Americ...|During the Americ...|\n        1910|A Lad from Old Ir...|        American|       Sidney Olcott|Sidney Olcott, Ge...|               drama|https://en.wikipe...|An Irish boy (Olc...|An Irish boy (Olc...|\n        1910|          Pocahontas|        American|             Unknown|Anna Rosemond, Ge...|       short fantasy|https://en.wikipe...|Though the film i...|Though the film i...|\n        1910|              Ramona|        American|      D. W. Griffith|Mary Pickford, He...|               drama|https://en.wikipe...|Ramona chronicles...|Ramona chronicles...|\n        1910| What the Daisy Said|        American|       D.W. Griffith|Clara T. Bracy, M...|             unknown|https://en.wikipe...|The film opens up...|The film opens up...|\n        1910|The Wonderful Wiz...|        American|Otis Turner (unco...|        Bebe Daniels|             unknown|https://en.wikipe...|In Kansas, Doroth...|In Kansas, Doroth...|\n+------------+--------------------+----------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\nonly showing top 36 rows\n\n</div>"]}}],"execution_count":37},{"cell_type":"code","source":["## check type\nmovies_spk #its a spark dataframe - good"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">15</span><span class=\"ansired\">]: </span>DataFrame[Release Year: string, Title: string, Origin/Ethnicity: string, Director: string, Cast: string, Genre: string, Wiki Page: string, Plot: string, All: string]</div>"]}}],"execution_count":38},{"cell_type":"code","source":["## have a look at schema\nmovies_spk.printSchema() #looks good"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">root\n-- Release Year: string (nullable = true)\n-- Title: string (nullable = true)\n-- Origin/Ethnicity: string (nullable = true)\n-- Director: string (nullable = true)\n-- Cast: string (nullable = true)\n-- Genre: string (nullable = true)\n-- Wiki Page: string (nullable = true)\n-- Plot: string (nullable = true)\n-- All: string (nullable = true)\n\n</div>"]}}],"execution_count":39},{"cell_type":"code","source":["## To test: Perform first SQL-query on dataframe (result is still an RDD)\nmovies_spk.registerTempTable(\"mov\")\nres1 = sqlContext.sql(\"select * from mov\\\n                      where Title == 'Inception'\")\nres1.show()\n\n# (takes about 4 s)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+------------+---------+----------------+-----------------+--------------------+---------------+--------------------+--------------------+--------------------+\nRelease Year|    Title|Origin/Ethnicity|         Director|                Cast|          Genre|           Wiki Page|                Plot|                 All|\n+------------+---------+----------------+-----------------+--------------------+---------------+--------------------+--------------------+--------------------+\n        2010|Inception|        American|Christopher Nolan|Leonardo DiCaprio...|science fiction|https://en.wikipe...|Dominick &quot;Dom&quot; Co...|Dominick &quot;Dom&quot; Co...|\n+------------+---------+----------------+-----------------+--------------------+---------------+--------------------+--------------------+--------------------+\n\n</div>"]}}],"execution_count":40},{"cell_type":"code","source":["## further test: run some spark transformations and actions:\nmovies_spk.select(\"Title\", \"Release Year\").filter(movies_spk[\"Release Year\"] > 2016).show(10) #works"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------------------+------------+\n               Title|Release Year|\n+--------------------+------------+\nUnderworld: Blood...|        2017|\n      Monster Trucks|        2017|\n     The Bye Bye Man|        2017|\n           Sleepless|        2017|\n         100 Streets|        2017|\n    The Book of Love|        2017|\n               Split|        2017|\nxXx: Return of Xa...|        2017|\nThe Resurrection ...|        2017|\n Trespass Against Us|        2017|\n+--------------------+------------+\nonly showing top 10 rows\n\n</div>"]}}],"execution_count":41},{"cell_type":"markdown","source":["Try to save the dataframe as parquet file... DOESNT WORK SO FAR"],"metadata":{}},{"cell_type":"code","source":["## write a parquet file for later use - DOESNT WORK...\n\n# Remove the file if it exists\n#dbutils.fs.rm(\"/tmp/movies_pq\", True)\n\n# then write\n#movies_spk.write.parquet(\"/tmp/movies_pq\")\n#movies_spk.write.parquet('C:\\\\Users\\\\sever\\\\Google Drive\\\\Dokumente PC\\\\ZHAW\\\\CAS Information Engineering\\\\Modul Big Data\\\\project\\\\performance_analysis_movie_recommender\\\\movies_pq')"],"metadata":{},"outputs":[],"execution_count":43},{"cell_type":"markdown","source":["Now, save the python list with the \"All\" variable as RDD:"],"metadata":{}},{"cell_type":"code","source":["## python list to RDD\npar_deg = \"automatically chosen\" #degree of parallelization - or is it stupid to set that manually?\nmovies_ls_rdd = sc.parallelize(movies_ls) #degree of parallelization chosen automatically"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":45},{"cell_type":"code","source":["## check the dada type\nmovies_ls_rdd # an RDD - good"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">18</span><span class=\"ansired\">]: </span>ParallelCollectionRDD[10] at readRDDFromFile at PythonRDD.scala:330</div>"]}}],"execution_count":46},{"cell_type":"code","source":["## run some basic operations on RDD\nprint(movies_ls_rdd.count())\nprint(movies_ls_rdd.takeSample(False, 1))\nprint(movies_ls_rdd.take(1))\n#works"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">34886\n[&apos;Frankie is a hard-drinking woman fresh out of a bad marriage. She wanders East Los Angeles looking for castoff furniture and clothing, which she sometimes sells for spending money. Otherwise, she hangs out with local musicians as an opportunity to meet people.\\r\\r\\nLev is a limousine driver who dreams of making it in the music business. He meets Frankie in a dive bar and they hook up, quickly escalating to the point where she moves in with him. Lev also makes a musical connection with Charlie King Nash, a well-known roots-rocker who has hit a creative wall and welcomes the chance to make a new start.\\r\\r\\nMeantime, Lev and Frankie try to work through the ups and downs of a serious relationship and decide whether each is ready for it.[1][2] 9 Full Moons 9 Full Moons 9 Full Moons 9 Full Moons 9 Full Moons 9 Full Moons 9 Full Moons 9 Full Moons 9 Full Moons 9 Full Moons American American American American American American American American American American Tomer Almagor Tomer Almagor Tomer Almagor Tomer Almagor Tomer Almagor Tomer Almagor Tomer Almagor Tomer Almagor Tomer Almagor Tomer Almagor Amy Seimetz, Bret Roberts, Donal Logue Amy Seimetz, Bret Roberts, Donal Logue Amy Seimetz, Bret Roberts, Donal Logue Amy Seimetz, Bret Roberts, Donal Logue Amy Seimetz, Bret Roberts, Donal Logue Amy Seimetz, Bret Roberts, Donal Logue Amy Seimetz, Bret Roberts, Donal Logue Amy Seimetz, Bret Roberts, Donal Logue Amy Seimetz, Bret Roberts, Donal Logue Amy Seimetz, Bret Roberts, Donal Logue dramadramadramadramadramadramadramadramadramadrama&apos;]\n[&quot;A bartender is working at a saloon, serving drinks to customers. After he fills a stereotypically Irish man&apos;s bucket with beer, Carrie Nation and her followers burst inside. They assault the Irish man, pulling his hat over his eyes and then dumping the beer over his head. The group then begin wrecking the bar, smashing the fixtures, mirrors, and breaking the cash register. The bartender then sprays seltzer water in Nation&apos;s face before a group of policemen appear and order everybody to leave.[1] Kansas Saloon Smashers Kansas Saloon Smashers Kansas Saloon Smashers Kansas Saloon Smashers Kansas Saloon Smashers Kansas Saloon Smashers Kansas Saloon Smashers Kansas Saloon Smashers Kansas Saloon Smashers Kansas Saloon Smashers American American American American American American American American American American Unknown Unknown Unknown Unknown Unknown Unknown Unknown Unknown Unknown Unknown nan nan nan nan nan nan nan nan nan nan unknownunknownunknownunknownunknownunknownunknownunknownunknownunknown&quot;]\n</div>"]}}],"execution_count":47},{"cell_type":"code","source":["## now a .map operation - which will be important later\n\n# goal: only take first 10 characters of text and swho the first three movies\nprint(movies_ls_rdd.map(lambda text: text[0:10]).take(3)) #works\n\n# goal: apply nor() function, take frst token of first three movies\nprint(movies_ls_rdd.map(lambda text: nor(text)).map(lambda ls: ls[0]).take(3)) #works"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">[&apos;A bartende&apos;, &apos;The moon, &apos;, &apos;The film, &apos;]\n[&apos;bartender&apos;, &apos;the&apos;, &apos;the&apos;]\n</div>"]}}],"execution_count":48},{"cell_type":"markdown","source":["###5. Create the spark helper functions\n\nWhat we want in this section is the following:\n\n- Parallalize the analysis in the two crucial steps (i.e. formulate the python helper functions as parallalizable spark-functions)"],"metadata":{}},{"cell_type":"markdown","source":["So now, lets re-formulate the the python helper functions for the recommender in \"spark language\". So that i can be parallelized on multiple clusters:"],"metadata":{}},{"cell_type":"code","source":["## normalizer function\n## THIS STAYS THE SAME AS IN THE PYTHON IMPLEMENTATION. NO CHANGE NEEDED.\n\n\ndef nor(txt):\n    \n    ''' doc:\n       input (txt) = text string that needs to be normalised\n       output = a list of normalised tokens - NOT UNIQUE!\n    '''\n    \n    ## tokenize\n    #txt_2 = nltk.word_tokenize(txt) # this causes problems in .map functionality later...\n    txt_2 = txt.split() #tokenize \n    \n    ## remove stopwords\n    txt_2 = [word for word in txt_2 if word not in stopw]\n    \n    ## remove special characters and capitals\n    txt_2 = [re.sub(r'\\W+', '', word).lower() for word in txt_2]\n    \n    ## remove empty indexes\n    txt_2 = [word for word in txt_2 if len(word)>1]\n    \n    # return result: a list of normalised tokens - NOT UNIQUE! - and joined with named entities\n    return txt_2"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":51},{"cell_type":"code","source":["## function for TF out of list of not-unique normalised tokens (result from nor() function)\n## THIS STAYS THE SAME AS IN THE PYTHON IMPLEMENTATION. NO CHANGE NEEDED.\n    \ndef tf(lis):\n    \n    ''' doc:\n       input: \n           lis = list of not-unique normalised tokens (result from nor() function)\n       output = a dict  with token and term freqencies\n    '''\n        \n    res = {} #dict of tokens in lis (key) and # occurances in lis (value)\n    cindex = set() #set of tokens in txt\n    \n    nt = len(lis) # number of tokens in txt\n    \n    # for every word in list\n    for t in lis:\n        if t not in cindex:\n            cindex.add(t)\n            res[t] = 1/nt # /nt gives the normalisation for the term-frequency\n        else:\n            res[t] += 1/nt\n    \n    ## return result - a dict of token and term freqencies\n    return res\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":52},{"cell_type":"code","source":["## idf function - SPARK VERSION\n\n# function that calculates idf for tokens in a collection of documents\n# returns a dict (key = token, velue = idf)\n\ndef idf_spk(coll):\n    \n    \"\"\"doc:\n    in: coll = list (RDD) of of documents (dociments = strings of multiple tokens)\n    out: pair of tokens and idf of token in collection\n    \"\"\" \n    \n    # count dumber of documents in collection\n    N = float(coll.count())\n    \n    # get a list of (non-unique) normalised tokens\n    lss = coll.flatMap(lambda doc: list(set(nor(doc)))) \n    \n    # build tuples: (token, 1) for all tokens in lss\n    token_count = lss.map(lambda token: (token, 1))\n    \n    # reduce: build tuple with (token, sum of occurances)\n    token_sum = token_count.reduceByKey(lambda a, b : a + b)\n    \n    # calculate idf and return pair with (token, idf)\n    return (token_sum.map(lambda tok: (tok[0], float(N/tok[1]))))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":53},{"cell_type":"code","source":["## test function\nidf_spk(sc.parallelize(movies_ls[:3],2)).collect() # seems ok\n#sc.parallelize(movies_ls[:10],2).flatMap(lambda doc: list(set(nor(doc)))).map(lambda token: (token, 1)).reduceByKey(lambda a, b : a + b).collect()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">16</span><span class=\"ansired\">]: </span>[(&apos;eight&apos;, 3.0),\n (&apos;saloon&apos;, 3.0),\n (&apos;bartender&apos;, 3.0),\n (&apos;fans&apos;, 3.0),\n (&apos;working&apos;, 3.0),\n (&apos;cash&apos;, 3.0),\n (&apos;policemen&apos;, 3.0),\n (&apos;last&apos;, 3.0),\n (&apos;mirrors&apos;, 3.0),\n (&apos;past&apos;, 3.0),\n (&apos;after&apos;, 3.0),\n (&apos;dumping&apos;, 3.0),\n (&apos;viewing&apos;, 3.0),\n (&apos;hat&apos;, 1.5),\n (&apos;presidents&apos;, 3.0),\n (&apos;garfield&apos;, 3.0),\n (&apos;assassin&apos;, 3.0),\n (&apos;altar&apos;, 3.0),\n (&apos;burst&apos;, 3.0),\n (&apos;bar&apos;, 3.0),\n (&apos;mckinleyeach&apos;, 3.0),\n (&apos;unknownunknownunknownunknownunknownunknownunknownunknownunknownunknown&apos;,\n  1.0),\n (&apos;group&apos;, 3.0),\n (&apos;tree&apos;, 3.0),\n (&apos;shoulder&apos;, 3.0),\n (&apos;eyes&apos;, 3.0),\n (&apos;long&apos;, 3.0),\n (&apos;smiling&apos;, 3.0),\n (&apos;fence&apos;, 3.0),\n (&apos;nation&apos;, 3.0),\n (&apos;portraits&apos;, 3.0),\n (&apos;water&apos;, 3.0),\n (&apos;stereotypically&apos;, 3.0),\n (&apos;nations&apos;, 3.0),\n (&apos;look&apos;, 3.0),\n (&apos;center&apos;, 3.0),\n (&apos;railing&apos;, 3.0),\n (&apos;kneels&apos;, 3.0),\n (&apos;head&apos;, 3.0),\n (&apos;three&apos;, 3.0),\n (&apos;bucket&apos;, 3.0),\n (&apos;at&apos;, 3.0),\n (&apos;bench&apos;, 3.0),\n (&apos;irish&apos;, 3.0),\n (&apos;sits&apos;, 3.0),\n (&apos;in&apos;, 1.5),\n (&apos;frown&apos;, 3.0),\n (&apos;love&apos;, 3.0),\n (&apos;young&apos;, 3.0),\n (&apos;assassination&apos;, 3.0),\n (&apos;scene&apos;, 3.0),\n (&apos;tomb&apos;, 3.0),\n (&apos;james&apos;, 3.0),\n (&apos;smiles&apos;, 3.0),\n (&apos;lady&apos;, 3.0),\n (&apos;hidden&apos;, 3.0),\n (&apos;night&apos;, 3.0),\n (&apos;unknown&apos;, 1.0),\n (&apos;moons&apos;, 3.0),\n (&apos;sky&apos;, 3.0),\n (&apos;appear&apos;, 3.0),\n (&apos;fills&apos;, 3.0),\n (&apos;fixtures&apos;, 3.0),\n (&apos;two&apos;, 3.0),\n (&apos;carrie&apos;, 3.0),\n (&apos;everything&apos;, 3.0),\n (&apos;sprays&apos;, 3.0),\n (&apos;us&apos;, 3.0),\n (&apos;painted&apos;, 3.0),\n (&apos;up&apos;, 3.0),\n (&apos;kansas&apos;, 3.0),\n (&apos;face&apos;, 1.0),\n (&apos;light&apos;, 3.0),\n (&apos;second&apos;, 3.0),\n (&apos;base&apos;, 3.0),\n (&apos;walking&apos;, 3.0),\n (&apos;martyred&apos;, 3.0),\n (&apos;followers&apos;, 3.0),\n (&apos;better&apos;, 3.0),\n (&apos;victims&apos;, 3.0),\n (&apos;the&apos;, 1.0),\n (&apos;presidentsabraham&apos;, 3.0),\n (&apos;displays&apos;, 3.0),\n (&apos;feet&apos;, 3.0),\n (&apos;mans&apos;, 3.0),\n (&apos;seltzer&apos;, 3.0),\n (&apos;customers&apos;, 3.0),\n (&apos;sit&apos;, 3.0),\n (&apos;nan&apos;, 1.0),\n (&apos;lincoln&apos;, 3.0),\n (&apos;seconds&apos;, 3.0),\n (&apos;couple&apos;, 3.0),\n (&apos;view&apos;, 3.0),\n (&apos;justice&apos;, 3.0),\n (&apos;causing&apos;, 3.0),\n (&apos;gets&apos;, 3.0),\n (&apos;first&apos;, 3.0),\n (&apos;left&apos;, 3.0),\n (&apos;embrace&apos;, 3.0),\n (&apos;hangs&apos;, 3.0),\n (&apos;serving&apos;, 3.0),\n (&apos;portal&apos;, 3.0),\n (&apos;smile&apos;, 3.0),\n (&apos;perched&apos;, 3.0),\n (&apos;minute&apos;, 3.0),\n (&apos;assault&apos;, 3.0),\n (&apos;girl&apos;, 3.0),\n (&apos;woman&apos;, 3.0),\n (&apos;park&apos;, 3.0),\n (&apos;shots&apos;, 3.0),\n (&apos;breaking&apos;, 3.0),\n (&apos;william&apos;, 3.0),\n (&apos;beer&apos;, 3.0),\n (&apos;pulling&apos;, 3.0),\n (&apos;drinks&apos;, 3.0),\n (&apos;man&apos;, 1.5),\n (&apos;shot&apos;, 3.0),\n (&apos;see&apos;, 3.0),\n (&apos;they&apos;, 1.5),\n (&apos;runs&apos;, 3.0),\n (&apos;film&apos;, 3.0),\n (&apos;inside&apos;, 3.0),\n (&apos;moon&apos;, 3.0),\n (&apos;everybody&apos;, 3.0),\n (&apos;smashers&apos;, 3.0),\n (&apos;american&apos;, 1.0),\n (&apos;begin&apos;, 3.0),\n (&apos;smashing&apos;, 3.0),\n (&apos;learn&apos;, 3.0),\n (&apos;blocked&apos;, 3.0),\n (&apos;composed&apos;, 3.0),\n (&apos;leave1&apos;, 3.0),\n (&apos;wrecking&apos;, 3.0),\n (&apos;register&apos;, 3.0),\n (&apos;camera&apos;, 3.0),\n (&apos;bigger&apos;, 3.0),\n (&apos;order&apos;, 3.0)]</div>"]}}],"execution_count":54},{"cell_type":"code","source":["# compare results of python and spark function!\n\nres_py = idf(movies_ls[:3]) # this is the python result\nprint(res_py)\n\nres_spk = idf_spk(sc.parallelize(movies_ls[:3],2))\nprint(res_spk.collect())\n\n# seems ok!"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">---------------------------------------------------------------------------</span>\n<span class=\"ansired\">NameError</span>                                 Traceback (most recent call last)\n<span class=\"ansigreen\">&lt;command-1388333490580178&gt;</span> in <span class=\"ansicyan\">&lt;module&gt;</span><span class=\"ansiblue\">()</span>\n<span class=\"ansigreen\">      1</span> <span class=\"ansired\"># compare results of python and spark function!</span><span class=\"ansiyellow\"></span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">      2</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">----&gt; 3</span><span class=\"ansiyellow\"> </span>res_py <span class=\"ansiyellow\">=</span> idf<span class=\"ansiyellow\">(</span>movies_ls<span class=\"ansiyellow\">[</span><span class=\"ansiyellow\">:</span><span class=\"ansicyan\">3</span><span class=\"ansiyellow\">]</span><span class=\"ansiyellow\">)</span> <span class=\"ansired\"># this is the python result</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">      4</span> print<span class=\"ansiyellow\">(</span>res_py<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">      5</span> <span class=\"ansiyellow\"></span>\n\n<span class=\"ansired\">NameError</span>: name &apos;idf&apos; is not defined</div>"]}}],"execution_count":55},{"cell_type":"code","source":["## tfidf function: combine tf with idf - function takes string and gives dict of tokens:tfidf\n## THIS STAYS THE SAME AS IN THE PYTHON IMPLEMENTATION. NO CHANGE NEEDED.\n\ndef tfidf(txt, idfs):\n    \"\"\" Compute TF-IDF\n    Args:\n        txt: string\n        idfs (dictionary): token to IDF value\n    Returns:\n        dictionary: a dictionary of records to TF-IDF values\n    \"\"\"\n    tfs = tf(nor(txt)) #a dict of token and term freqencies\n    \n    resdict = {}\n    \n    for t in tfs:\n        if t in idfs:\n            resdict[t] = tfs[t] * idfs[t] #calculate TF-IDF\n        else:\n            resdict[t] = 0 #zero if word is NOT in idfs reference\n            \n    return resdict"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":56},{"cell_type":"markdown","source":["Now the ranking function (only cossim-function is applied, as the comparison between the ranking functions is not the point of this project):"],"metadata":{}},{"cell_type":"code","source":["## implement cosine-similarity function(s)\n## THESE STAY THE SAME AS IN THE PYTHON IMPLEMENTATION. NO CHANGE NEEDED.\n\n# dot product and normalizing funs\ndef dotprod(a, b):\n    return sum([a[t] * b[t] for t in a if t in b])\n\ndef norm(a):\n    return math.sqrt(dotprod(a, a))\n\n# and finally, the actual fun to calculate cossim from two dicts\ndef cossim(dict1, dict2):\n    \"\"\" Compute cosine similarity between two strings\n    Args:\n        dict1: first dict of tokens and tf-idf values\n        dict2: second dict of tokens and tf-idf values\n\n    Returns:\n        cossim: cosine similarity value\n    \"\"\"\n\n    return dotprod(dict1, dict2) / norm(dict1) / norm(dict2)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":58},{"cell_type":"code","source":["## build ranking-function to compare query and corpus  - using cosine similarity\n    \ndef get_ranking_cossim_spk(query, ref_pairs, threshold, idf_dict):\n    \n    \"\"\" calculate and return a ranking of movies relative to searchstring (query)\n    input:\n        query = searchstring\n        ref_pairs = reference rdd pairs of movies (title:dict(token:tfidf))\n        threshold = threshold reference score above which results are returned\n        idf_dict = reference dict with term idfs as pairs of (token, idf)\n    output:\n        a sorted listof tuples (title, relevance score) with movies in decreasing similarity scores-order\n    \"\"\"\n    \n    ## first, apply tfidf() function to query\n    q = tfidf(query, idf_dict) #yields dict of query tokens:tfidf \n    \n    ## second, go over ref_pairs and compare query to values (calculate relevance score)\n        ## the result is a pair with movie titles as key and the relevance score (rs) as value\n      \n    result = (ref_pairs \n              .map(lambda film: (film[0], cossim(q,film[1]))))\n              \n    ## and return unordered result\n    return result #.takeOrdered(10, lambda s: -1*s[1]) #take the first 10 #---------------------------------- this is the problem... the sorting takes forever...\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":59},{"cell_type":"markdown","source":["###6. Apply the spark helper functions\n\nWhat we want in this section is the following:\n\n- Parallalize the analysis in the two crucial steps (i.e. apply the helper functions)\n- Time the (parallalized) crucial steps\n- Plot speed of parallalized version compared to baseline (maybe in next section...)"],"metadata":{}},{"cell_type":"code","source":["## prepare the timing of the spark-implementation\nspk_pre = time.time()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":61},{"cell_type":"markdown","source":["First, the idfs-reference dict"],"metadata":{}},{"cell_type":"code","source":["##First, apply the idf_spk function and build the spark idf-reference\nidfs_spk = idf_spk(movies_ls_rdd)#.cache() #lazy evaluation - only executed when action is called"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":63},{"cell_type":"code","source":["## check type\nidfs_spk #RDD, good"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">37</span><span class=\"ansired\">]: </span>PythonRDD[11] at RDD at PythonRDD.scala:57</div>"]}}],"execution_count":64},{"cell_type":"code","source":["## and show the results \n# idfs_spk.takeSample(False,3) #this is an action\n\n#takes only 2 min (on databricks community version)?! even without multiple clusters??"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":65},{"cell_type":"code","source":["# check result - seems ok\n# print(idfs_spk.count()) # number of tokens with idf-result"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":66},{"cell_type":"code","source":["## collect idfs dictionary as python dict to driver, and BROADCAST the variable\n## idf_spk() function is evaluated here - therefore it takes a while\n\nidfs_spk_dict = idfs_spk.collectAsMap() #we use the collectAsMap() action to return the IDFs to the driver as a Python dictionary.\nidfs_spk_dict_bc = sc.broadcast(idfs_spk_dict) #and we save it as broadcsted variable"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":67},{"cell_type":"code","source":["## check types\nprint(type(idfs_spk_dict))\nprint(type(idfs_spk_dict_bc))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">&lt;class &apos;dict&apos;&gt;\n&lt;class &apos;pyspark.broadcast.Broadcast&apos;&gt;\n</div>"]}}],"execution_count":68},{"cell_type":"markdown","source":["Now, make the \"movie reference dict\""],"metadata":{}},{"cell_type":"code","source":["## apply tfidf to  dataset (lazy eval)\nts_resdict_spk1 = time.time() #timestamp 1\n\n# go over movies (lazy evaluation)\nmovies_res_spk = (movies_spk #the dataframe of the whole dataset\n                  .select(\"Title\",\"All\") #select the two important columns\n                  .rdd #build an rdd (map functions cannot be applied to dataframes, it seems...)\n                  .map(lambda row: (row[0],tfidf(row[1], idfs_spk_dict_bc.value))) #map to make pair of (title, tfidf-dict of text) ------------- SROCKINGER: here the broadcasted, correct?(not if the movies_res variable is broadcsted a well?!)\n                  .cache()) \n\nts_resdict_spk2 = time.time() #timestamp 2\nsecs_spk = round(ts_resdict_spk2 - ts_resdict_spk1,1) #analysis time\n\nprint(\"Analysed all movies in {} seconds. No surprise with lazy evaluation ;-)\".format(secs_spk))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Analysed all movies in 0.2 seconds. No surprise with lazy evaluation ;-)\n</div>"]}}],"execution_count":70},{"cell_type":"code","source":["## check result - takes a while\nprint(movies_res_spk) #an RDD, good\n#print(movies_res_spk.take(1)) #looks good\n#print(movies_res_spk.count()) #seems correct"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">PythonRDD[15] at RDD at PythonRDD.scala:57\n</div>"]}}],"execution_count":71},{"cell_type":"code","source":["## collect and broadcast the movies_res_spk RDD (doesn't work if i try to broadcast the RDD directly (Exception: It appears that you are attempting to broadcast an RDD or reference an RDD from an action or transformation. RDD transformations and actions can only be invoked by the driver,).)\n\n#movies_res_spk_coll = movies_res_spk.collect() #collect to driver - takes a while - use this later to time the effect of the broadcast var"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":72},{"cell_type":"code","source":["#  movies_res_spk_coll_bc = sc.broadcast(movies_res_spk_coll) # and broadcast\n#  movies_res_spk_coll_bc #show type\n\n# this works. however, i think its not necessary as the get_ranking_cossim_spk function takes an rdd as input"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":73},{"cell_type":"markdown","source":["*Note:* The whole thing is way faster than with the python code - even without parallelization"],"metadata":{}},{"cell_type":"markdown","source":["##### Now test the whole recommender:"],"metadata":{}},{"cell_type":"code","source":["#quickly re-test tfidf() function\ntfidf(\"a test bond\", idfs_spk_dict_bc.value) # good"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">46</span><span class=\"ansired\">]: </span>{&apos;bond&apos;: 22.741851368970014, &apos;test&apos;: 18.24581589958159}</div>"]}}],"execution_count":76},{"cell_type":"code","source":["## then apply ranking-function (lazy evaluation again)\nquery_test = \"France action drama new test movie tarantino\"\n\nresult_q1 = get_ranking_cossim_spk(query = query_test, ref_pairs = movies_res_spk, threshold = 0.1, idf_dict = idfs_spk_dict_bc.value)\n# result_q1 = get_ranking_cossim_spk(query = query_test, ref_pairs = movies_res_spk_coll_bc.value, threshold = 0.1, idf_dict = idfs_spk_dict_bc.value) #------- does not work with the broadcasted movies_res_spk_coll_bc"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":77},{"cell_type":"code","source":["## type?\nresult_q1 #rdd"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">27</span><span class=\"ansired\">]: </span>PythonRDD[27] at RDD at PythonRDD.scala:57</div>"]}}],"execution_count":78},{"cell_type":"code","source":["## and show results (get_ranking_cossim_spk function is evaluated here (and the definition of movies_res_spk is also only evaluated here) - therefore this step takes long with cold cache (i.e. not-yet-cached movies_res_spk))\n\n#result_q1.take(100) #takes only 3s\n\n# do the ordering on the result of the get_ranking_cossim_spk function:\nresult_q1.takeOrdered(10, lambda s: -1*s[1]) # this (sorting) used to take long! why??\n\n# works!\n\n## note:\n# cold cache (first time): ca. 1.3 min\n# warm cache (starting second time): under 2 seconds\n\n# I think the point here might be the cashing of the movies_res_spk dict. Once this happened (and it happens in the first iteration of the code) the sorting is way faster...\n# when the cashing does not happen (in the definition of the movies_res_spk variable) the code takes 1.2 min in any iteration!"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">28</span><span class=\"ansired\">]: </span>[(&quot;My Best Friend&apos;s Birthday&quot;, 0.9545999944036624),\n (&apos;Reservoir Dogs&apos;, 0.7145623063126616),\n (&apos;From Dusk Till Dawn&apos;, 0.46822197465547655),\n (&apos;Kill Bill Volume 2&apos;, 0.32420709837713296),\n (&apos;Kill Bill Volume 1&apos;, 0.3174109851105095),\n (&apos;Girl 6&apos;, 0.21924820278988907),\n (&apos;Jackie Brown&apos;, 0.09054316914467836),\n (&apos;Django Unchained&apos;, 0.0834438438437147),\n (&apos;Pulp Fiction&apos;, 0.08048703631350722),\n (&apos;Inglourious Basterds&apos;, 0.03678268856492387)]</div>"]}}],"execution_count":79},{"cell_type":"code","source":["## and manifest the timing for the python implementation\n#spk_post = time.time()\nprint(\"The spark-implementation (20 cores) took {} seconds overall.\".format(round((spk_post - spk_pre),1)))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">The spark-implementation (20 cores) took 23.5 seconds overall.\n</div>"]}}],"execution_count":80},{"cell_type":"markdown","source":["###7. Multiply the dataset - for sepeed scaling experiment\n\nWhat we want in this section is the following:\n\n- multiply the two important RDDs (movies_spk, movies_ls_rdd). That is, create a new RDD that is just x times the old RDDs repeated.\n- run the critical steps (i.e. ...) on 1, 2 and 4 nodes and see how the speed of the multiplied RDDs scale.\n\n*Note:* \"par_deg\" in Cmd 43 has to be changed for the sensible use of multiple clusters... Best option is to choose the degree automatically."],"metadata":{}},{"cell_type":"code","source":["## cjeck degree of parallelization\npar_deg"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">26</span><span class=\"ansired\">]: </span>&apos;automatically chosen&apos;</div>"]}}],"execution_count":82},{"cell_type":"code","source":["## multiply the spark-datasets x 2\n\n# multiply how many times?\nmultipl_1 = 2\n\n# apply for movies_ls_rdd\nmovies_ls_rdd_mult2 = movies_ls_rdd.flatMap(lambda x: [x]*multipl_1)\n\n# and for movies_spk\nmovies_spk_mult2 = movies_spk\nitera1 = 1\nwhile itera1 < multipl_1:\n  movies_spk_mult2 = movies_spk_mult2.union(movies_spk)\n  itera1 += 1"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":83},{"cell_type":"code","source":["## multiply the spark-datasets x 4\n\n# multiply how many times?\nmultipl_2 = 4\n\n# apply for movies_ls_rdd\nmovies_ls_rdd_mult4 = movies_ls_rdd.flatMap(lambda x: [x]*multipl_2)\n\n# and for movies_spk\nmovies_spk_mult4 = movies_spk\nitera2 = 1\nwhile itera2 < multipl_2:\n  movies_spk_mult4 = movies_spk_mult4.union(movies_spk)\n  itera2 += 1"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":84},{"cell_type":"code","source":["## multiply the spark-datasets x 10\n\n# multiply how many times?\nmultipl_3 = 10\n\n# apply for movies_ls_rdd\nmovies_ls_rdd_mult10 = movies_ls_rdd.flatMap(lambda x: [x]*multipl_3)\n\n# and for movies_spk\nmovies_spk_mult10 = movies_spk\nitera3 = 1\nwhile itera3 < multipl_3:\n  movies_spk_mult10 = movies_spk_mult10.union(movies_spk)\n  itera3 += 1"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":85},{"cell_type":"code","source":["## see if it worked (numbers should be the same)\nprint(movies_ls_rdd.count() * 4)\nprint(movies_ls_rdd_mult2.count() * 2)\nprint(movies_ls_rdd_mult4.count())\nprint()\nprint(movies_spk.count() * 4)\nprint(movies_spk_mult2.count() * 2)\nprint(movies_spk_mult4.count())\nprint()\nprint(movies_spk_mult10.count()/10*4)\n\n# looks ok"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">139544\n139544\n139544\n\n139544\n139544\n139544\n\n139544.0\n</div>"]}}],"execution_count":86},{"cell_type":"markdown","source":["Now apply the \"critical function\" (i.e. the calculation of the idfs ref dict) for the multiplied datasets:"],"metadata":{}},{"cell_type":"code","source":["##First, apply the idf_spk function and build the spark idf-reference\nidfs_spk_mult1 = idf_spk(movies_ls_rdd) #lazy. this has been done above - but now new name for speed comparison\nidfs_spk_mult2 = idf_spk(movies_ls_rdd_mult2) #a lazy evaluation\nidfs_spk_mult4 = idf_spk(movies_ls_rdd_mult4) #again a lazy evaluation\nidfs_spk_mult10 = idf_spk(movies_ls_rdd_mult10) #again a lazy evaluation"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":88},{"cell_type":"markdown","source":["Now evaluate and compare running time - always make a list of 10 iterations of the *cold cache*-version of the respective analysis (action: count of total tokens - should be the same in all three cases as there are the same tokens)"],"metadata":{}},{"cell_type":"code","source":["## dataset x 1\n\n# result list\ntimes_dx1 = []\n\n# timing, 10 times\nfor i in range(10):\n  \n  # re-define idfs - so that the count() action later is always \"cold cache\" and the whole calculation is actually executed\n  idfs_spk_mult1 = idf_spk(movies_ls_rdd) #lazy.\n  \n  # then the timing\n  t1_1 = time.time()\n  idfs_spk_mult1.count()\n  t2_1 = time.time()\n\n  #append result to list\n  times_dx1.append(t2_1 - t1_1)\n  \n  # show progress\n  print(\"Iteration Nr. {} done ...\".format(i+1))\n\nprint()\nprint(\"The mean for the data x1 is {} seconds.\".format(round(numpy.mean(times_dx1),1)))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Iteration Nr. 1 done ...\nIteration Nr. 2 done ...\nIteration Nr. 3 done ...\nIteration Nr. 4 done ...\nIteration Nr. 5 done ...\nIteration Nr. 6 done ...\nIteration Nr. 7 done ...\nIteration Nr. 8 done ...\nIteration Nr. 9 done ...\nIteration Nr. 10 done ...\n\nThe mean for the data x1 is 6.9 seconds.\n</div>"]}}],"execution_count":90},{"cell_type":"code","source":["## dataset x 2\n\n# result list\ntimes_dx2 = []\n\n# timing, 10 times\nfor i in range(10):\n  \n  # re-define idfs - so that the count() action later is always \"cold cache\" and the whole calculation is actually executed\n  idfs_spk_mult2 = idf_spk(movies_ls_rdd_mult2)\n  \n  # then the timing\n  t1_2 = time.time()\n  idfs_spk_mult2.count()\n  t2_2 = time.time()\n\n  #append result to list\n  times_dx2.append(t2_2 - t1_2)\n  \n  # show progress\n  print(\"Iteration Nr. {} done ...\".format(i+1))\n\nprint()\nprint(\"The mean for the data x2 is {} seconds.\".format(round(numpy.mean(times_dx2),1)))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Iteration Nr. 1 done ...\nIteration Nr. 2 done ...\nIteration Nr. 3 done ...\nIteration Nr. 4 done ...\nIteration Nr. 5 done ...\nIteration Nr. 6 done ...\nIteration Nr. 7 done ...\nIteration Nr. 8 done ...\nIteration Nr. 9 done ...\nIteration Nr. 10 done ...\n\nThe mean for the data x2 is 12.2 seconds.\n</div>"]}}],"execution_count":91},{"cell_type":"code","source":["## dataset x 4\n\n# result list\ntimes_dx4 = []\n\n# timing, 10 times\nfor i in range(10):\n  \n  # re-define idfs - so that the count() action later is always \"cold cache\" and the whole calculation is actually executed\n  idfs_spk_mult4 = idf_spk(movies_ls_rdd_mult4)\n  \n  # then the timing\n  t1_4 = time.time()\n  idfs_spk_mult4.count()\n  t2_4 = time.time()\n\n  #append result to list\n  times_dx4.append(t2_4 - t1_4)\n  \n  # show progress\n  print(\"Iteration Nr. {} done ...\".format(i+1))\n\nprint()\nprint(\"The mean for the data x4 is {} seconds.\".format(round(numpy.mean(times_dx4),1)))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Iteration Nr. 1 done ...\nIteration Nr. 2 done ...\nIteration Nr. 3 done ...\nIteration Nr. 4 done ...\nIteration Nr. 5 done ...\nIteration Nr. 6 done ...\nIteration Nr. 7 done ...\nIteration Nr. 8 done ...\nIteration Nr. 9 done ...\nIteration Nr. 10 done ...\n\nThe mean for the data x4 is 24.1 seconds.\n</div>"]}}],"execution_count":92},{"cell_type":"code","source":["## dataset x 10\n\n# result list\ntimes_dx10 = []\n\n# timing, 10 times\nfor i in range(10):\n  \n  # re-define idfs - so that the count() action later is always \"cold cache\" and the whole calculation is actually executed\n  idfs_spk_mult10 = idf_spk(movies_ls_rdd_mult10)\n  \n  # then the timing\n  t1_10 = time.time()\n  idfs_spk_mult10.count()\n  t2_10 = time.time()\n\n  #append result to list\n  times_dx10.append(t2_10 - t1_10)\n  \n  # show progress\n  print(\"Iteration Nr. {} done ...\".format(i+1))\n\nprint()\nprint(\"The mean for the data x10 is {} seconds.\".format(round(numpy.mean(times_dx10),1)))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Iteration Nr. 1 done ...\nIteration Nr. 2 done ...\nIteration Nr. 3 done ...\nIteration Nr. 4 done ...\nIteration Nr. 5 done ...\nIteration Nr. 6 done ...\nIteration Nr. 7 done ...\nIteration Nr. 8 done ...\nIteration Nr. 9 done ...\nIteration Nr. 10 done ...\n\nThe mean for the data x10 is 58.0 seconds.\n</div>"]}}],"execution_count":93},{"cell_type":"markdown","source":["Keep this for the DAG-visualization"],"metadata":{}},{"cell_type":"code","source":["# dataset x 10\nidfs_spk_mult10.count()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">34</span><span class=\"ansired\">]: </span>199210</div>"]}}],"execution_count":95},{"cell_type":"markdown","source":["Now, time the effect of the broadcast-variable in the"],"metadata":{}},{"cell_type":"code","source":["## apply tfidf to 4x dataset (lazy eval) - same as above, just again to time the broadcast-effect\n\n# go over movies (lazy evaluation) - WITH BROADCAST\nmovies_res_spk_bc = (movies_spk_mult10 #the dataframe of the whole dataset\n                  .select(\"Title\",\"All\") #select the two important columns\n                  .rdd #build an rdd (map functions cannot be applied to dataframes, it seems...)\n                  .map(lambda row: (row[0],tfidf(row[1], idfs_spk_dict_bc.value))) #here be the broadcast\n                  .cache()) \n\n# go over movies (lazy evaluation) - NO BROADCAST\nmovies_res_spk_nbc = (movies_spk_mult10 #the dataframe of the whole dataset\n                  .select(\"Title\",\"All\") #select the two important columns\n                  .rdd #build an rdd (map functions cannot be applied to dataframes, it seems...)\n                  .map(lambda row: (row[0],tfidf(row[1], idfs_spk_dict))) #here be the broadcast\n                  .cache()) "],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":97},{"cell_type":"code","source":["## broadcasted\nmovies_res_spk_coll_bc = movies_res_spk_bc.count() #collect to driver"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":98},{"cell_type":"code","source":["movies_res_spk_coll_bc"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">45</span><span class=\"ansired\">]: </span>348860</div>"]}}],"execution_count":99},{"cell_type":"code","source":["## non-broadcasted\nmovies_res_spk_coll_nbc = movies_res_spk_nbc.count() #collect to driver"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":100},{"cell_type":"code","source":["movies_res_spk_coll_nbc"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">47</span><span class=\"ansired\">]: </span>348860</div>"]}}],"execution_count":101},{"cell_type":"markdown","source":["The broadcast does not seem to do much... For reasons see the following text (from big data exercise week 4):\n\n\"The solution in (3c) works well for small datasets, but it requires Spark to (automatically) send the idfsSmallWeights variable to all the workers. If we didn't cache() similarities, then it might have to be recreated if we run similar() multiple times. This would cause Spark to send idfsSmallWeights every time.\nInstead, we can use a broadcast variable - we define the broadcast variable in the driver and then we can refer to it in each worker. Spark saves the broadcast variable at each worker, so it is only sent once.\"\n\nMayve, in our case, the idfs-dict is sent only once to each worker anyway... therefore its no wonder that the broadcast does not do much...?"],"metadata":{}}],"metadata":{"name":"BD_project_troesch_otter_v6","notebookId":99025326221631},"nbformat":4,"nbformat_minor":0}
